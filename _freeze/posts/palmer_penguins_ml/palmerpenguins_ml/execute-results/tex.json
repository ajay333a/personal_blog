{
  "hash": "d623b78416c8ebf7c979d541c0c1e979",
  "result": {
    "markdown": "---\ntitle: \"Predict the sex of the Penguin Species\"\nauthor: \"Ajay Shankar A\"\ndate: \"2023-11-21\"\nformat: \n  html: default\n  pdf: default\ncategories: [Machine Learning, EDA, Code, Analysis]\n---\n\n::: {.cell}\n\n:::\n\n\n\nBuilding a model to predict the sex of three species of penguins of **Palmer Penguins** data.\n\n::: callout-tip\nThis is my first Machine Learning project and I am still learning as of this date. This work is inspired by **Julia Silge** and you can find the original work by her in her [blog](https://juliasilge.com/blog/palmer-penguins/) and would like to thank her for the teachings in [Julia Silge -Youtube channel](https://www.youtube.com/@JuliaSilge)\n:::\n\n## Exploring the data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\nlibrary(palmerpenguins)\n\npenguins\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 344 x 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   <fct>   <fct>              <dbl>         <dbl>             <int>       <int>\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# i 334 more rows\n# i 2 more variables: sex <fct>, year <int>\n```\n:::\n:::\n\n\n\nThe data set is from *palmerpenguins* library which contains observations of Antarctic pebguins from the Palmer Archipelago. You can read more about how this dataset came to be in [this post on the RStudio Education blog](https://education.rstudio.com/blog/2020/07/palmerpenguins-cran/). Our modeling goal here is to predict [the sex of the penguins](https://github.com/rfordatascience/tidytuesday/blob/master/data/2020/2020-07-28/readme.md) using a classification model, based on other observations in the dataset.\n\nIt is easier to classify and predict species than the sex of the species as the different physical characteristics are what makes a species different from each other. But sex somewhat harder to predict.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins %>% filter(!is.na(sex)) %>% \n  ggplot(aes(flipper_length_mm, bill_length_mm, color = sex,\n             size = body_mass_g)) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~species) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](palmerpenguins_ml_files/figure-pdf/eda_data-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nFrom the above graph it looks like female penguins have smaller with differet bills. Now let's build a model but first remove `year` and `island` from the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins_df <- penguins %>% filter(!is.na(sex)) %>% select(-year, -island)\n\npenguins_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 333 x 6\n   species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex   \n   <fct>            <dbl>         <dbl>             <int>       <int> <fct> \n 1 Adelie            39.1          18.7               181        3750 male  \n 2 Adelie            39.5          17.4               186        3800 female\n 3 Adelie            40.3          18                 195        3250 female\n 4 Adelie            36.7          19.3               193        3450 female\n 5 Adelie            39.3          20.6               190        3650 male  \n 6 Adelie            38.9          17.8               181        3625 female\n 7 Adelie            39.2          19.6               195        4675 male  \n 8 Adelie            41.1          17.6               182        3200 female\n 9 Adelie            38.6          21.2               191        3800 male  \n10 Adelie            34.6          21.1               198        4400 male  \n# i 323 more rows\n```\n:::\n:::\n\n\n\n## Building a Model\n\nLet's start by loading the `tidymodels` package and splitting our data into training and testing sets.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nset.seed(123)\n\npenguin_split <- initial_split(penguins_df, strata = sex)\n\npenguins_train <- training(penguin_split)\npenguins_test <- testing(penguin_split)\n```\n:::\n\n\n\nAs data for building a model is not that large, let's create resamples of training data to evaluate the model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\npenguin_boot <- bootstraps(penguins_train)\n\npenguin_boot\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Bootstrap sampling \n# A tibble: 25 x 2\n   splits           id         \n   <list>           <chr>      \n 1 <split [249/93]> Bootstrap01\n 2 <split [249/91]> Bootstrap02\n 3 <split [249/90]> Bootstrap03\n 4 <split [249/91]> Bootstrap04\n 5 <split [249/85]> Bootstrap05\n 6 <split [249/87]> Bootstrap06\n 7 <split [249/94]> Bootstrap07\n 8 <split [249/88]> Bootstrap08\n 9 <split [249/95]> Bootstrap09\n10 <split [249/89]> Bootstrap10\n# i 15 more rows\n```\n:::\n:::\n\n\n\nLet's build and compare two different models, a *logistic regression* model and a *random forest* model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# logistic regression model\nglm_spec <- logistic_reg() %>%\n  set_engine(\"glm\")\n\nglm_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n\n```{.r .cell-code}\n# random forest model\n\nrf_spec <- rand_forest() %>%\n  set_mode(\"classification\") %>% \n  set_engine(\"ranger\")\n\nrf_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRandom Forest Model Specification (classification)\n\nComputational engine: ranger \n```\n:::\n:::\n\n\n\nNext let's start putting together a tidymodels `workflow()`, a helper object to help manage modeling pipelines with pieces that fit together like Lego blocks. Notice that there is no model yet: `Model: None`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_wf <- workflow() %>% \n  add_formula(sex ~ .)\n\npenguin_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n== Workflow ====================================================================\nPreprocessor: Formula\nModel: None\n\n-- Preprocessor ----------------------------------------------------------------\nsex ~ .\n```\n:::\n:::\n\n\n\nNow we can add a model and fit the model to each of the resamples. First, we can fit the logistic regression model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_rs <- penguin_wf %>%\n  add_model(glm_spec) %>%\n  fit_resamples(\n    resamples = penguin_boot,\n    control = control_resamples(save_pred = TRUE)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n> A | warning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThere were issues with some computations   A: x1\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThere were issues with some computations   A: x3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\n```\n:::\n\n```{.r .cell-code}\nglm_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Bootstrap sampling \n# A tibble: 25 x 5\n   splits           id          .metrics         .notes           .predictions\n   <list>           <chr>       <list>           <list>           <list>      \n 1 <split [249/93]> Bootstrap01 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 2 <split [249/91]> Bootstrap02 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 3 <split [249/90]> Bootstrap03 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 4 <split [249/91]> Bootstrap04 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 5 <split [249/85]> Bootstrap05 <tibble [3 x 4]> <tibble [1 x 3]> <tibble>    \n 6 <split [249/87]> Bootstrap06 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 7 <split [249/94]> Bootstrap07 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 8 <split [249/88]> Bootstrap08 <tibble [3 x 4]> <tibble [1 x 3]> <tibble>    \n 9 <split [249/95]> Bootstrap09 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n10 <split [249/89]> Bootstrap10 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n# i 15 more rows\n\nThere were issues with some computations:\n\n  - Warning(s) x3: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\nRun `show_notes(.Last.tune.result)` for more information.\n```\n:::\n:::\n\n\n\nSecond, we can fit the random forest model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_rs <- penguin_wf %>%\n  add_model(rf_spec) %>%\n  fit_resamples(\n    resamples = penguin_boot,\n    control = control_resamples(save_pred = TRUE)\n  )\n\nrf_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Bootstrap sampling \n# A tibble: 25 x 5\n   splits           id          .metrics         .notes           .predictions\n   <list>           <chr>       <list>           <list>           <list>      \n 1 <split [249/93]> Bootstrap01 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 2 <split [249/91]> Bootstrap02 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 3 <split [249/90]> Bootstrap03 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 4 <split [249/91]> Bootstrap04 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 5 <split [249/85]> Bootstrap05 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 6 <split [249/87]> Bootstrap06 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 7 <split [249/94]> Bootstrap07 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 8 <split [249/88]> Bootstrap08 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n 9 <split [249/95]> Bootstrap09 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n10 <split [249/89]> Bootstrap10 <tibble [3 x 4]> <tibble [0 x 3]> <tibble>    \n# i 15 more rows\n```\n:::\n:::\n\n\n\nWe have fit each of our candidate models to our resampled training set!\n\n## Evaluate Model\n\nNow let's check the results and how well they performed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(glm_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 6\n  .metric     .estimator   mean     n std_err .config             \n  <chr>       <chr>       <dbl> <int>   <dbl> <chr>               \n1 accuracy    binary     0.918     25 0.00639 Preprocessor1_Model1\n2 brier_class binary     0.0585    25 0.00424 Preprocessor1_Model1\n3 roc_auc     binary     0.979     25 0.00254 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\ncollect_notes(glm_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 4\n  id          location                    type    note                          \n  <chr>       <chr>                       <chr>   <chr>                         \n1 Bootstrap05 preprocessor 1/1, model 1/1 warning glm.fit: fitted probabilities~\n2 Bootstrap08 preprocessor 1/1, model 1/1 warning glm.fit: fitted probabilities~\n3 Bootstrap23 preprocessor 1/1, model 1/1 warning glm.fit: fitted probabilities~\n```\n:::\n:::\n\n\n\nPretty nice! The function `collect_metrics()` extracts and formats the `.metrics` column from resampling results like the ones we have here.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(rf_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 6\n  .metric     .estimator   mean     n std_err .config             \n  <chr>       <chr>       <dbl> <int>   <dbl> <chr>               \n1 accuracy    binary     0.912     25 0.00547 Preprocessor1_Model1\n2 brier_class binary     0.0664    25 0.00240 Preprocessor1_Model1\n3 roc_auc     binary     0.977     25 0.00202 Preprocessor1_Model1\n```\n:::\n:::\n\n\n\nLet's choose *logistic regression model* as it is a simpler model than random forest.\n\nLet's check the confusion matrix for accuracy\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_rs %>% conf_mat_resampled()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 3\n  Prediction Truth   Freq\n  <fct>      <fct>  <dbl>\n1 female     female  41.1\n2 female     male     3  \n3 male       female   4.4\n4 male       male    42.3\n```\n:::\n:::\n\n\n\nNow for the `roc` curve which shows us how accurate a model is.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_rs %>%\n  collect_predictions() %>%\n  group_by(id) %>%\n  roc_curve(sex, .pred_female) %>%\n  ggplot(aes(1 - specificity, sensitivity, color = id)) +\n  geom_abline(lty = 2, color = \"gray80\", size = 1.5) +\n  geom_path(show.legend = FALSE, alpha = 0.6, linewidth = 1.2) +\n  coord_equal()\n```\n\n::: {.cell-output-display}\n![](palmerpenguins_ml_files/figure-pdf/roc_curve-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nIt is finally time for us to return to the testing set. Notice that we have not used the testing set yet during this whole analysis; the testing set is precious and can only be used to estimate performance on new data. Let's fit one more time to the training data and evaluate on the testing data using the function `last_fit()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_final <- penguin_wf %>%\n  add_model(glm_spec) %>%\n  last_fit(penguin_split)\n\npenguin_final\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Resampling results\n# Manual resampling \n# A tibble: 1 x 6\n  splits           id               .metrics .notes   .predictions .workflow \n  <list>           <chr>            <list>   <list>   <list>       <list>    \n1 <split [249/84]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n:::\n\n\n\nThe metrics and predictions here are on the testing data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(penguin_final)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 4\n  .metric     .estimator .estimate .config             \n  <chr>       <chr>          <dbl> <chr>               \n1 accuracy    binary         0.857 Preprocessor1_Model1\n2 roc_auc     binary         0.938 Preprocessor1_Model1\n3 brier_class binary         0.101 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\ncollect_predictions(penguin_final) %>%\n  conf_mat(sex, .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction female male\n    female     37    7\n    male        5   35\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_final$.workflow[[1]] %>%\n  tidy(exponentiate = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 5\n  term              estimate std.error statistic     p.value\n  <chr>                <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)       5.75e-46  19.6        -5.31  0.000000110\n2 speciesChinstrap  1.37e- 4   2.34       -3.79  0.000148   \n3 speciesGentoo     1.14e- 5   3.75       -3.03  0.00243    \n4 bill_length_mm    1.91e+ 0   0.180       3.60  0.000321   \n5 bill_depth_mm     8.36e+ 0   0.478       4.45  0.00000868 \n6 flipper_length_mm 1.06e+ 0   0.0611      0.926 0.355      \n7 body_mass_g       1.01e+ 0   0.00176     4.59  0.00000442 \n```\n:::\n:::\n\n\n\n-   The largest odds ratio is for bill depth, with the second largest for bill length. An increase of 1 mm in bill depth corresponds to almost 4x higher odds of being male. The characteristics of a penguin's bill must be associated with their sex.\n-   We don't have strong evidence that flipper length is different between male and female penguins, controlling for the other measures; maybe we should explore that by changing that first plot!\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins %>% filter(!is.na(sex)) %>% \n  ggplot(aes(bill_depth_mm, bill_length_mm, color = sex)) +\n  geom_point(alpha = 0.5) +\n  facet_wrap(~species) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](palmerpenguins_ml_files/figure-pdf/eda_final-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\nThis graph shows much more separation between male and female penguins.\n",
    "supporting": [
      "palmerpenguins_ml_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}